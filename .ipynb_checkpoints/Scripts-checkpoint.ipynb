{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da20a729-d295-47a1-b04e-4938dd7939cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Constants import abs_china, ABS_PRIDE, ballantine_poland, Abs_Valentine, Codigo, ABS_OCEAN_SPRAY,Oaken_Glow\n",
    "from prompts import dimension_extraction_prompt,dimension_value_extract_prompt\n",
    "from utils import deepseek_chat\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72add98-eebe-4a1d-96cf-c5d42be04334",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LIST = ['Campaign Theme',\n",
    "'Marketing Objectives',\n",
    "'Universal Consumer Challenge',\n",
    "'Local Consumer Challenge (Market-Specific)',\n",
    "'Brand Context/Heritage',\n",
    "'Campaign Ambition/Scope',\n",
    "'Target Audience (Strategic Segment)',\n",
    "'Audience Demographics/Behavior',\n",
    "'Single-Minded Message',\n",
    "'Tone of Voice',\n",
    "'Key Deliverables/Assets',\n",
    "'Success Metrics (KPIs)',\n",
    "'Mandatory Channels/Formats',\n",
    "'Representation/Inclusivity Guidelines',\n",
    "'Cultural Adaptation Requirements'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3fd61c-2136-4366-9a2d-2e8afcba89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_extract_dimensions(brief_text): \n",
    "    message = f'{dimension_extraction_prompt} and the input brief is {ABS_PRIDE}'\n",
    "    response = deepseek_chat(message)\n",
    "    return extract_dimensions(response)\n",
    "\n",
    "\n",
    "def extract_dimensions(text):\n",
    "    pattern = r'-\\s*\\*\\*(.*?)\\*\\*'\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a63c966-95a8-4a9e-8e79-64357a15e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Create a dictionary of your campaigns with extracted dimensions\n",
    "campaign_dict = {\n",
    "    'abs_china': llm_extract_dimensions(abs_china),\n",
    "    'abs_pride': llm_extract_dimensions(ABS_PRIDE),\n",
    "    'ballantine_poland': llm_extract_dimensions(ballantine_poland),\n",
    "    'Abs_Valentine': llm_extract_dimensions(Abs_Valentine),\n",
    "    'Codigo': llm_extract_dimensions(Codigo),\n",
    "    'ABS_OCEAN_SPRAY': llm_extract_dimensions(ABS_OCEAN_SPRAY),\n",
    "    'Oaken_Glow': llm_extract_dimensions(Oaken_Glow)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ae2ac22-d8cf-4c0e-a8a5-5aee205fdd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create DataFrame\n",
    "dimension_df = pd.DataFrame.from_dict(\n",
    "    campaign_dict, \n",
    "    orient='index'  # Use campaigns as rows\n",
    ").transpose() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbee4508-cb60-433c-8736-1bd85d11f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_df.to_csv('dimension_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a7c04-f0ee-4c22-b2ce-d50151cf3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pdfplumber\n",
    "\n",
    "# Extract text\n",
    "with pdfplumber.open(\"BALLANTINES-IBP-7.pdf\") as pdf:\n",
    "    full_text = \"\\n\".join(page.extract_text() for page in pdf.pages)\n",
    "\n",
    "# Split into semantic chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Adjust per content density\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")\n",
    "chunks = splitter.split_text(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795aa5e3-227f-4c2a-be27-6fc9426a3670",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fillin_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdimension_value_extract_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and the keys are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDIM_LIST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and the input chunk is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunk' is not defined"
     ]
    }
   ],
   "source": [
    "fillin_prompt = f\"{dimension_value_extract_prompt}, and the keys are {DIM_LIST}, and the input chunk is {chunk}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be4f133-3d67-4785-a99a-dd3add1e3c6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m chunks[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "test = chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e7f187-d048-4495-be6b-2c0abb236b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''BRAND\\nPRESENTATION DISCL AIMER\\nThis presentation is strictly confidential and contains highly sensitive and valuable information.\n",
    "\\nIts content as well as the methodology which is described herein are intended to be considered\\nas trade secrets for Pernod Ricard and \n",
    "must be treated as such.\\nThe content should not be (i) sent or forwarded to any other person or (ii) published or reproduced,\\nin whole \n",
    "or in part, through any medium or in any form for any purpose, without the prior written\\nconsent of Pernod Ricard. \n",
    "The presentation must be returned to Pernod Ricard and no hard\\nor electronic copy kept by the recipient.\\nCONFIDENTIAL\\nWELCOME\\n\n",
    "This fresh Brand World marks the beginning of Ballantine’s journey to becoming a true LIFESTYLE BRAND.\\nIt is built to reflect our\n",
    "vision — a brand with attitude.\\nOne that goes beyond \n",
    "product to inspire people to be their true selves.\\nTO A PREVIEW\\nThis evolution is grounded in what Ballantine’s has always stood for:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0812783a-a9f1-45d7-bfa8-1bbb342a77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set your DeepSeek API key (recommended to use environment variables)\n",
    "DEEPSEEK_API_KEY = \"sk-612784d0a4e1415e987a39dd4657426e\" \n",
    "DEEPSEEK_API_URL = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "MODEL_NAME = \"deepseek-chat\"  # Use appropriate model (e.g., \"deepseek-coder\" for code tasks)\n",
    "structured_data = []\n",
    "message = ''\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "SYSTEM_PROMPT =  f\"{dimension_value_extract_prompt}, and the keys are {DIM_LIST}\"\n",
    "\n",
    "message = f'{SYSTEM_PROMPT}, and input message is {test}'\n",
    "\n",
    "response = deepseek_chat(message)\n",
    "clean_response = response.strip('```json\\n').strip('```')\n",
    "# Parse the JSON string\n",
    "dict_data = json.loads(clean_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db9f6fd5-3c9e-4c63-a4d1-b466df6f318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_response = response.strip('```json\\n').strip('```')\n",
    "# Parse the JSON string\n",
    "dict_data = json.loads(clean_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae1d8f91-5f2a-4657-b34f-f11f91dbbacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSYSTEM_PROMPT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and input message is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunks' is not defined"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "    \n",
    "    message = f'{SYSTEM_PROMPT}, and input message is {chunk}'\n",
    "    \n",
    "    response = deepseek_chat(message)\n",
    "    clean_response = response.strip('```json\\n').strip('```')\n",
    "    # Parse the JSON string\n",
    "    dict_data = json.loads(clean_response)\n",
    "    \n",
    "    all_dict_data.append(dict_data)\n",
    "    print(f\"Processed chunk {i+1}\")\n",
    "\n",
    "# Now let's create word frequency distributions for each dimension\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text for frequency analysis\"\"\"\n",
    "    if not text or text.strip() == '':\n",
    "        return []\n",
    "    # Convert to lowercase, remove punctuation, split into words\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "    words = [word.strip() for word in text.split() if len(word.strip()) > 2]  # Remove very short words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7597446a-754b-4a5a-85ff-1a1f2525d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Campaign Theme': 'Becoming a true LIFESTYLE BRAND',\n",
       " 'Marketing Objectives': '',\n",
       " 'Universal Consumer Challenge': '',\n",
       " 'Local Consumer Challenge (Market-Specific)': '',\n",
       " 'Brand Context/Heritage': 'Ballantine’s has always stood for a brand with attitude',\n",
       " 'Campaign Ambition/Scope': 'To inspire people to be their true selves',\n",
       " 'Target Audience (Strategic Segment)': '',\n",
       " 'Audience Demographics/Behavior': '',\n",
       " 'Single-Minded Message': '',\n",
       " 'Tone of Voice': '',\n",
       " 'Key Deliverables/Assets': '',\n",
       " 'Success Metrics (KPIs)': '',\n",
       " 'Mandatory Channels/Formats': '',\n",
       " 'Representation/Inclusivity Guidelines': '',\n",
       " 'Cultural Adaptation Requirements': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.strip('```json\\n').strip('```'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606388c2-2a21-4451-849c-105b37227694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf0a6cd-c839-4791-931a-72370224dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are a marketing analyst AI. Below is a marketing brief in plain text, followed by a finalized list of dimensions.\\nYour task is to extract the most relevant value for each dimension based on the content of the brief. If a dimension is not mentioned or not clearly stated, leave it blank (do not guess).\\nOnly Return Output JSON with keys \\n, and the keys are ['Campaign Theme', 'Marketing Objectives', 'Universal Consumer Challenge', 'Local Consumer Challenge (Market-Specific)', 'Brand Context/Heritage', 'Campaign Ambition/Scope', 'Target Audience (Strategic Segment)', 'Audience Demographics/Behavior', 'Single-Minded Message', 'Tone of Voice', 'Key Deliverables/Assets', 'Success Metrics (KPIs)', 'Mandatory Channels/Formats', 'Representation/Inclusivity Guidelines', 'Cultural Adaptation Requirements'], and input message is BRAND\\nPRESENTATION DISCL AIMER\\nThis presentation is strictly confidential and contains highly sensitive and valuable information.\\n\\nIts content as well as the methodology which is described herein are intended to be considered\\nas trade secrets for Pernod Ricard and \\nmust be treated as such.\\nThe content should not be (i) sent or forwarded to any other person or (ii) published or reproduced,\\nin whole \\nor in part, through any medium or in any form for any purpose, without the prior written\\nconsent of Pernod Ricard. \\nThe presentation must be returned to Pernod Ricard and no hard\\nor electronic copy kept by the recipient.\\nCONFIDENTIAL\\nWELCOME\\n\\nThis fresh Brand World marks the beginning of Ballantine’s journey to becoming a true LIFESTYLE BRAND.\\nIt is built to reflect our\\nvision — a brand with attitude.\\nOne that goes beyond \\nproduct to inspire people to be their true selves.\\nTO A PREVIEW\\nThis evolution is grounded in what Ballantine’s has always stood for:\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44b294-afd9-445b-b260-0c2ef8029dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facff9d6-8287-43f3-adc7-6cf4f4dbf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# Generate vectors\n",
    "vectors = model.encode([item[\"text\"] for item in structured_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3cc33-987e-4789-8e5b-42ae1c1e8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"martell_db\")\n",
    "collection = client.create_collection(\"brand_attributes\")\n",
    "\n",
    "# Add to vector DB\n",
    "collection.add(\n",
    "    ids=[d[\"chunk_id\"] for d in structured_data],\n",
    "    embeddings=vectors.tolist(),\n",
    "    metadatas=[d[\"metadata\"] for d in structured_data],\n",
    "    documents=[d[\"text\"] for d in structured_data]  # Keep raw text for fallback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b4be6-9990-4253-8a98-dbca7af96198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_attribute(query: str, attribute: str) -> str:\n",
    "    # 1. Semantic search\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=3,\n",
    "        include=[\"metadatas\", \"documents\"]\n",
    "    )\n",
    "    \n",
    "    # 2. Extract relevant values\n",
    "    candidate_values = []\n",
    "    for metadata in results[\"metadatas\"][0]:\n",
    "        if attribute in metadata and metadata[attribute]:\n",
    "            candidate_values.extend(metadata[attribute])\n",
    "    \n",
    "    # 3. Resolve conflicts via LLM if needed\n",
    "    if not candidate_values:\n",
    "        return None\n",
    "    elif len(set(candidate_values)) == 1:\n",
    "        return candidate_values[0]\n",
    "    else:\n",
    "        # Use LLM to choose best value\n",
    "        return llm_resolve_conflict(candidate_values, query, attribute)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
